{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### downloadHandler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA not available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import face_recognition\n",
    "from pytube import YouTube\n",
    "import easyocr\n",
    "import face_recognition\n",
    "import json\n",
    "import os\n",
    "import moviepy.editor as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from Levenshtein import distance\n",
    "reader = easyocr.Reader(['en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_by_url(vid_url, video_save_path=\"video\", audio_save_path=\"audio\"):\n",
    "    vid = YouTube(vid_url)\n",
    "    vid_stream = vid.streams.filter(\n",
    "        file_extension=\"mp4\").get_highest_resolution()\n",
    "    vid_path = vid_stream.download(video_save_path)\n",
    "    vid_json = {}\n",
    "    vid_json[\"vidname\"] = vid.title\n",
    "    vid_json[\"url\"] = vid_url\n",
    "    vid_json[\"res\"] = vid_stream.resolution\n",
    "    vid_json[\"mimetype\"] = vid_stream.mime_type\n",
    "    vid_json[\"fps\"] = vid_stream.fps\n",
    "    vid_json[\"filepath\"] = vid_path\n",
    "    jsonfile = video_save_path+\"/\"+vid_stream.default_filename[0:-3]+\"json\"\n",
    "    with open(jsonfile, 'w') as f:\n",
    "        f.write(json.dumps(vid_json))\n",
    "    # print(vid_path, \"downloaded\")\n",
    "\n",
    "    return vid_path, vid_json\n",
    "\n",
    "\n",
    "def video_to_audio(video_path, output_path):\n",
    "    clip = mp.VideoFileClip(\"{}\".format(video_path))\n",
    "    filename = os.path.basename(video_path)[:-4] + '.wav'\n",
    "    print(\"processing audio {}\".format(filename))\n",
    "    output_path = os.path.join(output_path, filename)\n",
    "    clip.audio.write_audiofile(\"{}\".format(output_path))\n",
    "    print('{} is processed'.format(output_path))\n",
    "\n",
    "\n",
    "def analyze_video(video, start_frame=0, end_frame=None, sampling_rate=1):\n",
    "    \"\"\"Find chicken dinner in video\"\"\"\n",
    "    w, h, fps, num_frames = get_detail(video)\n",
    "    print(w, h, fps, num_frames)\n",
    "    start_frame = start_frame\n",
    "    end_frame = end_frame if end_frame else num_frames\n",
    "    step = int(round(sampling_rate * fps))\n",
    "    start = time.time()\n",
    "    cap = cv2.VideoCapture(video)\n",
    "    i = start_frame\n",
    "    output = []\n",
    "    all_res = []\n",
    "    while cap.isOpened() and i < end_frame:\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "#         print(i)\n",
    "        ret, frame = cap.read()\n",
    "#         print(frame)\n",
    "#         try:\n",
    "        temp_res = run_inference(frame)\n",
    "#         except:\n",
    "#             return frame\n",
    "        all_res.append(temp_res)\n",
    "        i += step\n",
    "\n",
    "    cap.release()\n",
    "    end = time.time()\n",
    "\n",
    "    return {\n",
    "        'start_frame': start_frame,\n",
    "        'end_frame': end_frame,\n",
    "        'result_feature': all_res,\n",
    "        'step': step,\n",
    "        'fps': fps\n",
    "    }\n",
    "\n",
    "\n",
    "def get_detail(vid_file):\n",
    "    cap = cv2.VideoCapture(vid_file)\n",
    "\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(\n",
    "        cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return width, height, fps, total_frames\n",
    "\n",
    "\n",
    "def run_inference(frame):\n",
    "    all_text_here = reader.readtext(frame)  # OCR\n",
    "    all_faces_locations = face_recognition.face_locations(frame)\n",
    "    all_faces_features_here = face_recognition.face_encodings(frame)  # FACE\n",
    "\n",
    "    return {\n",
    "        'text': all_text_here\n",
    "#         'faces_location': all_faces_locations,\n",
    "#         'faces_features': all_faces_features_here\n",
    "    }\n",
    "\n",
    "\n",
    "def np_encoder(object):\n",
    "    if isinstance(object, np.generic):\n",
    "        return object.item()\n",
    "\n",
    "\n",
    "def distance_text(a, b):\n",
    "    if max(len(a), len(b)) == 0:\n",
    "        return 1\n",
    "    return distance(a, b)/max(len(a), len(b))\n",
    "\n",
    "\n",
    "def reshape_text(data1, data2, idx):\n",
    "    for word in data2:\n",
    "        used_word = word[1].lower()\n",
    "        found = False\n",
    "        for key in data1.keys():\n",
    "            dist = distance_text(key, used_word)\n",
    "            if dist < 0.1:\n",
    "\n",
    "                if data1[key][-1]['end']+1 == idx:\n",
    "                    data1[key][-1]['end'] += 1\n",
    "                else:\n",
    "                    data1[key].append({'start': idx, 'end': idx})\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            #             print('word : ',word[1].lower())\n",
    "            #             print(data1)\n",
    "            data1[used_word] = [{'start': idx, 'end': idx}]\n",
    "    return data1\n",
    "\n",
    "\n",
    "def aggregate_text(all_text):\n",
    "    aggregated_text = {}\n",
    "    for idx, txt in enumerate(all_text):\n",
    "        aggregated_text = reshape_text(aggregated_text, txt, idx)\n",
    "    return aggregated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = download_by_url('https://www.youtube.com/watch?v=VxTS_y48p8Q%26list=PLnm7lhAd02yEsiFPZUsx_-JpWbt2-2xb_%26index=5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('D:\\\\facerecog-proj\\\\ocr\\\\video\\\\NO DONT DO THAT.mp4',\n",
       " {'vidname': \"NO DON'T DO THAT\",\n",
       "  'url': 'https://www.youtube.com/watch?v=VxTS_y48p8Q%26list=PLnm7lhAd02yEsiFPZUsx_-JpWbt2-2xb_%26index=5',\n",
       "  'res': '720p',\n",
       "  'mimetype': 'video/mp4',\n",
       "  'fps': 30,\n",
       "  'filepath': 'D:\\\\facerecog-proj\\\\ocr\\\\video\\\\NO DONT DO THAT.mp4'})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'index' is required to be an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-30870921b355>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyze_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-f9c0379ca5e2>\u001b[0m in \u001b[0;36manalyze_video\u001b[1;34m(video, start_frame, end_frame, sampling_rate)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0manalyze_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;34m\"\"\"Find chicken dinner in video\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_detail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mstart_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-f9c0379ca5e2>\u001b[0m in \u001b[0;36mget_detail\u001b[1;34m(vid_file)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_detail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvid_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mtotal_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCAP_PROP_FRAME_COUNT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'index' is required to be an integer"
     ]
    }
   ],
   "source": [
    "result = analyze_video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube\n",
      "  Downloading pytube-10.8.4-py3-none-any.whl (46 kB)\n",
      "Installing collected packages: pytube\n",
      "  Attempting uninstall: pytube\n",
      "    Found existing installation: pytube 10.8.2\n",
      "    Uninstalling pytube-10.8.2:\n",
      "      Successfully uninstalled pytube-10.8.2\n",
      "Successfully installed pytube-10.8.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
