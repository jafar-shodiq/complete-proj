{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## July 22 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 7.515970945358276\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "df = pd.read_feather('D:/internship-telkom/data-science/slow-connection/CW02_dataset.ftr')\n",
    "print('Time elapsed: {}'.format((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 name  score1  score2  score3  score4  scoremin1  report\n",
      "0   int_latency_score   81.16    5.02    2.16    3.96       7.70       0\n",
      "1   int_latency_score   75.63    5.46    2.36    4.49      12.06       1\n",
      "2   ext_latency_score   89.06    2.31    0.26    0.27       8.09       0\n",
      "3   ext_latency_score   84.37    2.02    0.25    0.30      13.05       1\n",
      "4    fd_latency_score   43.43   26.71    9.32   14.78       5.76       0\n",
      "5    fd_latency_score   39.53   24.77    9.05   15.98      10.66       1\n",
      "6     int_ploss_score   70.85   25.91    1.48    1.55       0.21       0\n",
      "7     int_ploss_score   66.52   26.66    1.98    2.22       2.63       1\n",
      "8     ext_ploss_score   86.79   10.36    0.67    0.65       1.54       0\n",
      "9     ext_ploss_score   82.98   11.22    0.94    2.60       2.26       1\n",
      "10    ses_setup_score   89.32    8.03    1.59    0.88       0.17       0\n",
      "11    ses_setup_score   88.63    8.04    1.97    1.05       0.31       1\n",
      "12    ser_acces_score   19.77   49.97   21.45    8.61       0.20       0\n",
      "13    ser_acces_score   22.92   46.38   21.34    9.04       0.32       1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_feather('D:/big-datasets/internship-telkom/CW02_dataset.ftr')\n",
    "\n",
    "def make_df_bin(bin_1h, sample):\n",
    "    cols = ['user_id', 'date_time', 'reportdate', 'bin_1h', 'int_latency_score', 'ext_latency_score', 'fd_latency_score',\n",
    "            'int_ploss_score', 'ext_ploss_score', 'ses_setup_score', 'ser_acces_score']\n",
    "\n",
    "    report1 = df[cols][(df['bin_1h'] >= bin_1h) & (df['bin_1h'] < 0)].drop_duplicates().sample(sample)\n",
    "    report1.drop('user_id', axis=1, inplace=True)\n",
    "    report1['report_0_1'] = 1\n",
    "    \n",
    "    report0 = df[cols][(df['bin_1h'] < bin_1h) | (df['bin_1h'] > 0)].drop_duplicates().sample(sample)\n",
    "    report0.drop('user_id', axis=1, inplace=True)\n",
    "    report0['report_0_1'] = 0\n",
    "    \n",
    "    df_report = pd.concat([report1, report0])\n",
    "    return df_report\n",
    "\n",
    "        \n",
    "def make_df_score(score_name, bin_1h=-48, sample=100000):\n",
    "    try:\n",
    "        cols = ['name', 'score1', 'score2', 'score3', 'score4', 'scoremin1', 'report']\n",
    "        score_lst = [1, 2, 3, 4, -1]\n",
    "\n",
    "        df_report = make_df_bin(bin_1h, sample)\n",
    "        df_score = pd.DataFrame(columns=cols)\n",
    "        df_score['report'] = [0, 1]\n",
    "        for n1, score in zip(range(1, 6), score_lst):\n",
    "            for n2 in range(0, 2):\n",
    "                df_score[cols[n1]][df_score['report'] == n2] = df_report[(df_report['report_0_1'] == n2) &\n",
    "                                                                         (df_report[score_name] == score)].shape[0]                                                                  \n",
    "        df_score['name'] = score_name\n",
    "        return df_score\n",
    "    except:\n",
    "        print('Error! Please specify less smaller sample size.')\n",
    "\n",
    "\n",
    "cols = [col for col in df.columns if 'score' in col]\n",
    "\n",
    "df_conc = pd.concat([make_df_score(cols[0]), make_df_score(cols[1]), make_df_score(cols[2]), make_df_score(cols[3]),\n",
    "                     make_df_score(cols[4]), make_df_score(cols[5]), make_df_score(cols[6])])\n",
    "df_conc.reset_index(drop=True, inplace=True)\n",
    "df_conc[['score1', 'score2', 'score3', 'score4', 'scoremin1']] = round(df_conc[['score1', 'score2', 'score3', 'score4', 'scoremin1']].astype(int) / 1000, 2)\n",
    "print(df_conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
